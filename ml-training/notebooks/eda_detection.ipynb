{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17fa32ae",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619b358b",
   "metadata": {},
   "source": [
    "## 2. Load Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f73984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "DATA_DIR = Path('data/detection')\n",
    "IMAGES_DIR = DATA_DIR / 'images'\n",
    "LABELS_DIR = DATA_DIR / 'labels'\n",
    "\n",
    "# Count images\n",
    "train_images = list((IMAGES_DIR / 'train').glob('*'))\n",
    "val_images = list((IMAGES_DIR / 'val').glob('*'))\n",
    "\n",
    "print(f\"Dataset Statistics:\")\n",
    "print(f\"  Training images: {len(train_images)}\")\n",
    "print(f\"  Validation images: {len(val_images)}\")\n",
    "print(f\"  Total: {len(train_images) + len(val_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f92737",
   "metadata": {},
   "source": [
    "## 3. Image Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7504a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_stats(image_path):\n",
    "    \"\"\"Extract image statistics\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    return {\n",
    "        'width': img.width,\n",
    "        'height': img.height,\n",
    "        'format': img.format,\n",
    "        'size_mb': os.path.getsize(image_path) / (1024 * 1024)\n",
    "    }\n",
    "\n",
    "# Collect statistics\n",
    "stats = []\n",
    "all_images = train_images + val_images\n",
    "\n",
    "for img_path in all_images[:min(100, len(all_images))]:\n",
    "    try:\n",
    "        stat = get_image_stats(img_path)\n",
    "        stats.append(stat)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "df_stats = pd.DataFrame(stats)\n",
    "\n",
    "print(f\"\\nImage Dimensions:\")\n",
    "print(df_stats[['width', 'height']].describe())\n",
    "print(f\"\\nFile Sizes (MB):\")\n",
    "print(df_stats['size_mb'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac8ed7",
   "metadata": {},
   "source": [
    "## 4. Annotation Analysis (YOLO Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa09123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_yolo_annotation(label_path):\n",
    "    \"\"\"Parse YOLO format annotation file\"\"\"\n",
    "    annotations = []\n",
    "    if label_path.exists():\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    annotations.append({\n",
    "                        'class_id': int(parts[0]),\n",
    "                        'x_center': float(parts[1]),\n",
    "                        'y_center': float(parts[2]),\n",
    "                        'width': float(parts[3]),\n",
    "                        'height': float(parts[4])\n",
    "                    })\n",
    "    return annotations\n",
    "\n",
    "# Count annotations\n",
    "annotation_count = 0\n",
    "annotation_list = []\n",
    "\n",
    "for img_path in train_images[:min(100, len(train_images))]:\n",
    "    label_path = (LABELS_DIR / 'train' / img_path.stem).with_suffix('.txt')\n",
    "    annotations = parse_yolo_annotation(label_path)\n",
    "    annotation_count += len(annotations)\n",
    "    annotation_list.extend(annotations)\n",
    "\n",
    "print(f\"Total annotations in sample: {annotation_count}\")\n",
    "print(f\"Average annotations per image: {annotation_count / min(100, len(train_images)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2de4ab",
   "metadata": {},
   "source": [
    "## 5. Annotation Size Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23de03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if annotation_list:\n",
    "    df_annotations = pd.DataFrame(annotation_list)\n",
    "    \n",
    "    # Calculate actual sizes\n",
    "    df_annotations['box_area'] = df_annotations['width'] * df_annotations['height']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Box width distribution\n",
    "    axes[0, 0].hist(df_annotations['width'], bins=30, color='skyblue', edgecolor='black')\n",
    "    axes[0, 0].set_title('Bounding Box Width Distribution')\n",
    "    axes[0, 0].set_xlabel('Normalized Width')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Box height distribution\n",
    "    axes[0, 1].hist(df_annotations['height'], bins=30, color='lightcoral', edgecolor='black')\n",
    "    axes[0, 1].set_title('Bounding Box Height Distribution')\n",
    "    axes[0, 1].set_xlabel('Normalized Height')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    \n",
    "    # Box area distribution\n",
    "    axes[1, 0].hist(df_annotations['box_area'], bins=30, color='lightgreen', edgecolor='black')\n",
    "    axes[1, 0].set_title('Bounding Box Area Distribution')\n",
    "    axes[1, 0].set_xlabel('Normalized Area')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # X-center distribution\n",
    "    axes[1, 1].hist(df_annotations['x_center'], bins=30, color='lightyellow', edgecolor='black')\n",
    "    axes[1, 1].set_title('Horizontal Position Distribution')\n",
    "    axes[1, 1].set_xlabel('Normalized X Center')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nBounding Box Statistics:\")\n",
    "    print(df_annotations[['width', 'height', 'box_area']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9077c361",
   "metadata": {},
   "source": [
    "## 6. Visualize Sample Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_annotation(image_path, label_path, ax):\n",
    "    \"\"\"Visualize image with bounding boxes\"\"\"\n",
    "    img = cv2.imread(str(image_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # type: ignore\n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.set_title(image_path.name)\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    annotations = parse_yolo_annotation(label_path)\n",
    "    for ann in annotations:\n",
    "        x_center = ann['x_center'] * width\n",
    "        y_center = ann['y_center'] * height\n",
    "        w = ann['width'] * width\n",
    "        h = ann['height'] * height\n",
    "        \n",
    "        x1 = int(x_center - w/2)\n",
    "        y1 = int(y_center - h/2)\n",
    "        x2 = int(x_center + w/2)\n",
    "        y2 = int(y_center + h/2)\n",
    "        \n",
    "        rect = plt.Rectangle((x1, y1), w, h, fill=False, edgecolor='red', linewidth=2) # type: ignore\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    ax.axis('off')\n",
    "\n",
    "# Visualize samples\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, img_path in enumerate(train_images[:6]):\n",
    "    label_path = (LABELS_DIR / 'train' / img_path.stem).with_suffix('.txt')\n",
    "    visualize_annotation(img_path, label_path, axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Sample annotations visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed78f4",
   "metadata": {},
   "source": [
    "## 7. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f2c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_quality():\n",
    "    \"\"\"Perform data quality checks\"\"\"\n",
    "    issues = {\n",
    "        'missing_labels': 0,\n",
    "        'corrupted_images': 0,\n",
    "        'empty_images': 0,\n",
    "        'invalid_annotations': 0\n",
    "    }\n",
    "    \n",
    "    for split in ['train', 'val']:\n",
    "        image_dir = IMAGES_DIR / split\n",
    "        label_dir = LABELS_DIR / split\n",
    "        \n",
    "        for img_path in image_dir.glob('*'):\n",
    "            # Check if label exists\n",
    "            label_path = (label_dir / img_path.stem).with_suffix('.txt')\n",
    "            if not label_path.exists():\n",
    "                issues['missing_labels'] += 1\n",
    "                continue\n",
    "            \n",
    "            # Check image validity\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                if img.size[0] == 0 or img.size[1] == 0:\n",
    "                    issues['empty_images'] += 1\n",
    "            except Exception as e:\n",
    "                issues['corrupted_images'] += 1\n",
    "            \n",
    "            # Check annotation validity\n",
    "            try:\n",
    "                annotations = parse_yolo_annotation(label_path)\n",
    "                for ann in annotations:\n",
    "                    if not (0 <= ann['x_center'] <= 1 and \n",
    "                           0 <= ann['y_center'] <= 1 and\n",
    "                           0 < ann['width'] <= 1 and\n",
    "                           0 < ann['height'] <= 1):\n",
    "                        issues['invalid_annotations'] += 1\n",
    "            except:\n",
    "                issues['invalid_annotations'] += 1\n",
    "    \n",
    "    return issues\n",
    "\n",
    "quality_issues = check_data_quality()\n",
    "\n",
    "print(\"\\nData Quality Report:\")\n",
    "print(\"=\"*40)\n",
    "for issue, count in quality_issues.items():\n",
    "    status = \"✓\" if count == 0 else \"⚠\"\n",
    "    print(f\"{status} {issue}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44cd1a6",
   "metadata": {},
   "source": [
    "## 8. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ca110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATASET ANALYSIS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nDataset Size:\")\n",
    "print(f\"  Train: {len(train_images)} images\")\n",
    "print(f\"  Val: {len(val_images)} images\")\n",
    "print(f\"  Total: {len(train_images) + len(val_images)} images\")\n",
    "\n",
    "if df_stats is not None:\n",
    "    print(f\"\\nImage Properties:\")\n",
    "    print(f\"  Avg Width: {df_stats['width'].mean():.0f} px\")\n",
    "    print(f\"  Avg Height: {df_stats['height'].mean():.0f} px\")\n",
    "    print(f\"  Avg Size: {df_stats['size_mb'].mean():.2f} MB\")\n",
    "\n",
    "print(f\"\\nAnnotations:\")\n",
    "print(f\"  Total in sample: {annotation_count}\")\n",
    "print(f\"  Avg per image: {annotation_count / min(100, len(train_images)):.2f}\")\n",
    "\n",
    "print(f\"\\nRecommendations:\")\n",
    "print(f\"  • Image size for training: 640x480 (YOLO standard)\")\n",
    "print(f\"  • Batch size: 32-64 (adjust based on GPU memory)\")\n",
    "print(f\"  • Model: YOLOv8n or YOLOv8s for edge deployment\")\n",
    "print(f\"  • Epochs: 100-150 with early stopping\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
